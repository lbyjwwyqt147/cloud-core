server:
  port: 18080
  tomcat:
    uri-encoding: utf-8

#配置外部访问文件（把上传的文件放到E盘下的fileUpload文件夹下）
data:
  file:
    dir: /opt/uploadWorkspace
  # 配置系统访问url
  hostName: http://101.132.136.225:18080/
  # 域名设置 跨域
  allowedOrigin: '*'
  # 直接访问 http://101.132.136.225:18080 时 返回信息设置
  indexView: '请访问：http://101.132.136.225:18080/swagger-ui.html  查看API文档'
  # 数据字典地址
  dictUrl: http://127.0.0.1:18080/api/v1/dict/dictName
  # cloud_core 地址
  cloudUrl: http://127.0.0.1:18080/api/v1
  # redis 是否默填充application name 作为redis key 的前缀   true 填充 false 不填充   例如：photo_album:user    photo_album:为自动填充
  redisPrefixion: true
  # 授权访问核心系统的 code
  coreSystemCode: 1000
  # 授权访问核心系统的 appId
  coreAppId: 1550817758252
  # 授权访问核心系统的 appKey
  coreAppKey: c80e645007264e2684b393533ef7e832
  # 授权访问核心系统的 credential
  coreCredential: 1f2db1ad91963708d36c751c282be8ae

spring:
  datasource:
    # 使用阿里的Druid连接池
    type: com.alibaba.druid.pool.DruidDataSource
    # JDBC 配置
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://127.0.0.1:3306/cloud_core?useUnicode=true&characterEncoding=UTF-8&useSSL=false&serverTimezone=CTT&rewriteBatchedStatements=true&autoReconnect=true
    username: root
    password: root@123
    druid:
      # 连接池配置
      # 初始化大小，最小，最大
      initial-size: 50
      min-idle: 10
      max-active: 100
      # 配置一个连接在池中最小生存的时间，单位是毫秒
      min-evictable-idle-time-millis: 300000
      # max-evictable-idle-time-millis: 600000
      max-open-prepared-statements: 60000
      max-pool-prepared-statement-per-connection-size: 20
      max-wait: 60000
      pool-prepared-statements: true
      test-on-borrow: false
      test-on-return: false
      test-while-idle: true
      time-between-eviction-runs-millis: 60000
      validation-query: SELECT 1 FROM DUAL
      validation-query-timeout: 60000
      transaction-threshold-millis: 60000
      remove-abandoned-timeout-millis: 30000
      filters: stat,wall,log4j2  # 配置监控统计拦截的filters,采用log4j2作为日志实现
      # 通过connectProperties属性来打开mergeSql功能；慢SQL记录
      connection-properties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000
      # 监控配置　WebStatFilter配置
      web-stat-filter:
        enabled: true
        exclusions: '*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*'
        principal-cookie-name: admin
        principal-session-name: admin
        profile-enable: true
        session-stat-enable: false
        session-stat-max-count: 1000
        url-pattern: '/*'
      stat-view-servlet:
        # IP 白名单
        allow: 127.0.0.1
        #  IP黑名单(共同存在时，deny优先于allow)
        deny: 192.168.0.10
        enabled: true
        # 控制台用户名和密码
        login-password: admin
        login-username: admin
        reset-enable: false
        url-pattern: '/druid/*'
      # 配置日志输出
      filter:
        slf4j:
          enabled: true
          statement-create-after-log-enabled: false
          statement-close-after-log-enabled: false
          result-set-open-after-log-enabled: false

  # elasticsearch 配置
  data:
    elasticsearch:
      #节点的地址 注意api模式下端口号是9300，千万不要写成9200
      cluster-nodes: 127.0.0.1:9300
      # elasticsearch集群名称，默认的是elasticsearch
      cluster-name: docker-cluster
      properties:
        path:
          logs: ./elasticsearch/log # elasticsearch日志存储目录
          data: ./elasticsearch/data # elasticsearch数据存储目录
        transport:
          tcp:
            connect_timeout: 120s  # 连接超时的时间

  # redis 配置
  redis:
    host: 127.0.0.1
    port: 6379
    password:
    database: 1
    jedis:
      pool:
        #最大连接数
        max-active: 500
        #最大空闲
        max-idle: 20
        #最大阻塞等待时间(负数表示没限制)
        max-wait: 50000ms
        #最小空闲
        min-idle: 10
    #连接超时时间
    timeout: 60000ms

logging:
  config: classpath:log4j2-spring-prod.xml

